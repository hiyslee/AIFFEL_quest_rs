{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ Transformer (ê°œì„ ëœ ë²„ì „)\n",
        "\n",
        "## ì£¼ìš” ê°œì„  ì‚¬í•­\n",
        "| í•­ëª© | ê¸°ì¡´ | ê°œì„  |\n",
        "|------|------|------|\n",
        "| d_model | 256 | **512** |\n",
        "| ffn_dim | 1024 | **2048** |\n",
        "| Learning Rate | ê³ ì • 0.0005 | **Warmup Scheduler** |\n",
        "| Epochs | 30 | **50** |\n",
        "| Early Stopping | 3 | **7** |\n",
        "| ë²ˆì—­ ë°©ì‹ | Greedy | **Beam Search ì¶”ê°€** |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install -q sentencepiece easydict koeda gensim\n",
        "\n",
        "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "# ë°ì´í„° ì²˜ë¦¬\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "try:\n",
        "    from nltk.corpus import wordnet\n",
        "    wordnet.synsets('test')\n",
        "except LookupError:\n",
        "    print(\"WordNet ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# SentencePiece\n",
        "import sentencepiece as spm\n",
        "\n",
        "# ì‹œê°í™”\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# í‰ê°€\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# ì§„í–‰ë°”\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ì„¤ì •\n",
        "from easydict import EasyDict\n",
        "\n",
        "# ê²½ê³  ë¬´ì‹œ\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# ëœë¤ ì‹œë“œ ì„¤ì •\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. ë””ë ‰í† ë¦¬ ë° ê²½ë¡œ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "dataset_dir = '/content/work/dataset'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = '/content/work/dataset'\n",
        "ENG_TRAIN_PATH = f'{DATA_DIR}/augmented_train.en'\n",
        "KOR_TRAIN_PATH = f'{DATA_DIR}/augmented_train.ko'\n",
        "\n",
        "# ì €ì¥ ê²½ë¡œ\n",
        "MODEL_DIR = '/content/work/models'\n",
        "TOKENIZER_DIR = '/content/work/tokenizers'\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(TOKENIZER_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_SAVE_PATH = f'{MODEL_DIR}/transformer_improved.pt'\n",
        "ENG_TOKENIZER_PREFIX = f'{TOKENIZER_DIR}/kor_eng'\n",
        "KOR_TOKENIZER_PREFIX = f'{TOKENIZER_DIR}/eng_kor'\n",
        "\n",
        "print(\"âœ… ê²½ë¡œ ì„¤ì • ì™„ë£Œ!\")\n",
        "print(f\"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}\")\n",
        "print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. â­ ê°œì„ ëœ ì„¤ì • (í•µì‹¬ ë³€ê²½!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì„¤ì •\n",
        "DATA_CONFIG = EasyDict({\n",
        "    'train_ratio': 0.8,\n",
        "    'val_ratio': 0.1,\n",
        "    'test_ratio': 0.1,\n",
        "    'max_length': 60,\n",
        "    'vocab_size_eng': 8000,\n",
        "    'vocab_size_kor': 8000,\n",
        "    'batch_size': 64,          # 128 â†’ 64 (ëª¨ë¸ í¬ê¸° ì¦ê°€ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "    'num_workers': 0,\n",
        "})\n",
        "\n",
        "# â­ ê°œì„ ëœ ëª¨ë¸ ì„¤ì •\n",
        "MODEL_CONFIG = EasyDict({\n",
        "    'emb_dim': 512,            # 256 â†’ 512 (í•µì‹¬ ê°œì„ !)\n",
        "    'ffn_dim': 2048,           # 1024 â†’ 2048 (í•µì‹¬ ê°œì„ !)\n",
        "    'num_heads': 8,\n",
        "    'encoder_layers': 6,\n",
        "    'decoder_layers': 6,\n",
        "    'dropout': 0.1,\n",
        "    'attention_dropout': 0.1,\n",
        "    'max_position_embeddings': 128,\n",
        "})\n",
        "\n",
        "# â­ ê°œì„ ëœ í•™ìŠµ ì„¤ì •\n",
        "TRAIN_CONFIG = EasyDict({\n",
        "    'num_epochs': 50,          # 30 â†’ 50 (ë” ë§ì€ í•™ìŠµ)\n",
        "    'warmup_steps': 4000,      # í•µì‹¬ ì¶”ê°€! Warmup steps\n",
        "    'betas': (0.9, 0.98),\n",
        "    'eps': 1e-9,\n",
        "    'weight_decay': 0.0001,    # 0.01 â†’ 0.0001 (ë‚®ì¶¤)\n",
        "    'clip': 1.0,\n",
        "    'label_smoothing': 0.1,\n",
        "    'patience': 7,             # 3 â†’ 7 (ë” ì¸ë‚´ì‹¬ ìˆê²Œ)\n",
        "    'min_delta': 1e-4,\n",
        "})\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… ê°œì„ ëœ ì„¤ì • ì™„ë£Œ!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ëª¨ë¸ í¬ê¸°: d_model={MODEL_CONFIG.emb_dim}, ffn_dim={MODEL_CONFIG.ffn_dim}\")\n",
        "print(f\"ë°°ì¹˜ í¬ê¸°: {DATA_CONFIG.batch_size}\")\n",
        "print(f\"Warmup Steps: {TRAIN_CONFIG.warmup_steps}\")\n",
        "print(f\"ì´ Epochs: {TRAIN_CONFIG.num_epochs}\")\n",
        "print(f\"Early Stopping Patience: {TRAIN_CONFIG.patience}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "print(\"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
        "!wget -q https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz -P {dataset_dir}\n",
        "!gzip -df {dataset_dir}/korean-english-park.train.tar.gz 2>/dev/null || true\n",
        "!tar -xf {dataset_dir}/korean-english-park.train.tar -C {dataset_dir} 2>/dev/null || true\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„° ê²½ë¡œ\n",
        "kor_path = os.path.join(dataset_dir, \"korean-english-park.train.ko\")\n",
        "eng_path = os.path.join(dataset_dir, \"korean-english-park.train.en\")\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "with open(kor_path, 'r', encoding='utf-8') as f:\n",
        "    questions = [line.strip() for line in f.readlines()]\n",
        "\n",
        "with open(eng_path, 'r', encoding='utf-8') as f:\n",
        "    answers = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(f\"\\në‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"í•œêµ­ì–´ ë¬¸ì¥ ê°œìˆ˜: {len(questions):,}\")\n",
        "print(f\"ì˜ì–´ ë¬¸ì¥ ê°œìˆ˜: {len(answers):,}\")\n",
        "print(f\"\\nì˜ˆì‹œ:\")\n",
        "for i in range(2):\n",
        "    print(f\"Kor: {questions[i][:50]}...\")\n",
        "    print(f\"Eng: {answers[i][:50]}...\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def preprocess_sentence(sentence: str, lang: str = 'kor') -> str:\n",
        "    sentence = sentence.strip()\n",
        "    if lang == 'eng':\n",
        "        sentence = sentence.lower()\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
        "    return sentence.strip()\n",
        "\n",
        "def preprocess_data_v2(eng_sentences, kor_sentences, show_samples=2):\n",
        "    \"\"\"ê°•í™”ëœ ì „ì²˜ë¦¬ (ì¤‘ë³µ ì œê±° + í’ˆì§ˆ í•„í„°ë§)\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘... (v2: ê°•í™”ëœ ë²„ì „)\")\n",
        "    \n",
        "    eng_processed = [preprocess_sentence(s, 'eng') for s in tqdm(eng_sentences, desc=\"ì˜ì–´\")]\n",
        "    kor_processed = [preprocess_sentence(s, 'kor') for s in tqdm(kor_sentences, desc=\"í•œêµ­ì–´\")]\n",
        "    \n",
        "    filtered_pairs = []\n",
        "    seen_pairs = set()\n",
        "    stats = {'length': 0, 'duplicate': 0, 'no_text': 0, 'too_short': 0, 'ratio': 0}\n",
        "    \n",
        "    for e, k in zip(eng_processed, kor_processed):\n",
        "        e_words, k_words = len(e.split()), len(k.split())\n",
        "        \n",
        "        if not (3 <= e_words <= 50 and 2 <= k_words <= 60):\n",
        "            stats['length'] += 1\n",
        "            continue\n",
        "        \n",
        "        pair_key = (k, e)\n",
        "        if pair_key in seen_pairs:\n",
        "            stats['duplicate'] += 1\n",
        "            continue\n",
        "        seen_pairs.add(pair_key)\n",
        "        \n",
        "        if not re.search(r'[ê°€-í£]', k) or not re.search(r'[a-z]', e):\n",
        "            stats['no_text'] += 1\n",
        "            continue\n",
        "        \n",
        "        if len(k) < 5 or len(e) < 10:\n",
        "            stats['too_short'] += 1\n",
        "            continue\n",
        "        \n",
        "        ratio = e_words / k_words if k_words > 0 else 0\n",
        "        if not (0.5 <= ratio <= 3.0):\n",
        "            stats['ratio'] += 1\n",
        "            continue\n",
        "        \n",
        "        filtered_pairs.append((e, k))\n",
        "    \n",
        "    eng_filtered, kor_filtered = zip(*filtered_pairs) if filtered_pairs else ([], [])\n",
        "    eng_filtered, kor_filtered = list(eng_filtered), list(kor_filtered)\n",
        "    \n",
        "    original = len(eng_sentences)\n",
        "    final = len(eng_filtered)\n",
        "    print(f\"\\nğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼: {original:,} â†’ {final:,} ({final/original*100:.1f}%)\")\n",
        "    print(f\"ì œê±°: ê¸¸ì´({stats['length']}), ì¤‘ë³µ({stats['duplicate']}), ë¹„ìœ¨({stats['ratio']})\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if show_samples > 0:\n",
        "        print(f\"\\nğŸ“‹ ìƒ˜í”Œ ({show_samples}ê°œ)\")\n",
        "        for i in random.sample(range(len(eng_filtered)), min(show_samples, len(eng_filtered))):\n",
        "            print(f\"ğŸ‡°ğŸ‡· {kor_filtered[i][:50]}...\")\n",
        "            print(f\"ğŸ‡ºğŸ‡¸ {eng_filtered[i][:50]}...\\n\")\n",
        "    \n",
        "    return eng_filtered, kor_filtered\n",
        "\n",
        "# ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "eng_filtered, kor_filtered = preprocess_data_v2(answers, questions, show_samples=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. ë°ì´í„° ì¦ê°• (30%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KoEDA ì¦ê°•\n",
        "try:\n",
        "    from koeda import EDA\n",
        "    \n",
        "    class KoEDAugmenter:\n",
        "        def __init__(self):\n",
        "            print(\"KoEDA ì´ˆê¸°í™” ì¤‘...\")\n",
        "            self.eda = EDA(morpheme_analyzer=\"Okt\", alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, prob_rd=0.1)\n",
        "            print(\"âœ… KoEDA ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "        def augment(self, sentence, num_aug=1):\n",
        "            if len(sentence.split()) <= 1:\n",
        "                return []\n",
        "            try:\n",
        "                result = self.eda(sentence)\n",
        "                augmented = [result] if isinstance(result, str) else result\n",
        "                return [s for s in augmented if s != sentence and len(s.strip()) > 0]\n",
        "            except:\n",
        "                return []\n",
        "    \n",
        "    KOEDA_AVAILABLE = True\n",
        "except:\n",
        "    KOEDA_AVAILABLE = False\n",
        "    print(\"âš ï¸ KoEDA ë¯¸ì„¤ì¹˜\")\n",
        "\n",
        "# ë°ì´í„° ë¶„í• \n",
        "train_ko, temp_ko, train_en, temp_en = train_test_split(\n",
        "    kor_filtered, eng_filtered, test_size=0.2, random_state=SEED\n",
        ")\n",
        "val_ko, test_ko, val_en, test_en = train_test_split(\n",
        "    temp_ko, temp_en, test_size=0.5, random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"ë°ì´í„° ë¶„í• : Train={len(train_ko):,}, Val={len(val_ko):,}, Test={len(test_ko):,}\")\n",
        "\n",
        "# 30% ì¦ê°•\n",
        "if KOEDA_AVAILABLE:\n",
        "    AUGMENT_RATIO = 0.3\n",
        "    AUGMENT_NEEDED = int(len(train_ko) * AUGMENT_RATIO)\n",
        "    \n",
        "    print(f\"\\nì¦ê°• ëª©í‘œ: {AUGMENT_NEEDED:,}ê°œ (30%)\")\n",
        "    \n",
        "    augmenter = KoEDAugmenter()\n",
        "    \n",
        "    # ì¦ê°•í•  ìƒ˜í”Œ ì„ íƒ\n",
        "    aug_indices = random.sample(range(len(train_ko)), min(AUGMENT_NEEDED, len(train_ko)))\n",
        "    \n",
        "    aug_ko, aug_en = [], []\n",
        "    for idx in tqdm(aug_indices, desc=\"ì¦ê°• ì¤‘\"):\n",
        "        augmented = augmenter.augment(train_ko[idx])\n",
        "        if augmented:\n",
        "            aug_ko.append(augmented[0])\n",
        "            aug_en.append(train_en[idx])\n",
        "    \n",
        "    # ì›ë³¸ + ì¦ê°•\n",
        "    train_ko = list(train_ko) + aug_ko\n",
        "    train_en = list(train_en) + aug_en\n",
        "    \n",
        "    # ì…”í”Œ\n",
        "    combined = list(zip(train_ko, train_en))\n",
        "    random.shuffle(combined)\n",
        "    train_ko, train_en = zip(*combined)\n",
        "    train_ko, train_en = list(train_ko), list(train_en)\n",
        "    \n",
        "    print(f\"\\nâœ… ì¦ê°• ì™„ë£Œ! Train: {len(train_ko):,}ê°œ\")\n",
        "\n",
        "# ì €ì¥\n",
        "with open(KOR_TRAIN_PATH, 'w', encoding='utf-8') as f:\n",
        "    for s in train_ko: f.write(s + '\\n')\n",
        "with open(ENG_TRAIN_PATH, 'w', encoding='utf-8') as f:\n",
        "    for s in train_en: f.write(s + '\\n')\n",
        "\n",
        "print(f\"ğŸ“ ì €ì¥ ì™„ë£Œ: {KOR_TRAIN_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. í† í¬ë‚˜ì´ì € ì •ì˜ ë° í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sentencepiece(data, model_prefix, vocab_size=8000):\n",
        "    print(f\"SentencePiece í•™ìŠµ: {model_prefix}\")\n",
        "    corpus_path = f'{model_prefix}_corpus.txt'\n",
        "    with open(corpus_path, 'w', encoding='utf-8') as f:\n",
        "        for line in data:\n",
        "            f.write(f'{line}\\n')\n",
        "    \n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        f'--input={corpus_path} --model_prefix={model_prefix} --vocab_size={vocab_size} '\n",
        "        f'--model_type=unigram --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --character_coverage=1.0'\n",
        "    )\n",
        "    os.remove(corpus_path)\n",
        "    print(f\"âœ… ì™„ë£Œ: {model_prefix}.model\")\n",
        "\n",
        "\n",
        "class SentencePieceVocab:\n",
        "    def __init__(self, model_path):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(model_path)\n",
        "        self.PAD_ID, self.UNK_ID, self.BOS_ID, self.EOS_ID = 0, 1, 2, 3\n",
        "        self.itos = [self.sp.IdToPiece(i) for i in range(self.sp.GetPieceSize())]\n",
        "\n",
        "    def encode(self, text): return self.sp.EncodeAsIds(text)\n",
        "    def decode(self, ids): return self.sp.DecodeIds([i for i in ids if i not in [0,2,3]])\n",
        "    def __len__(self): return self.sp.GetPieceSize()\n",
        "\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € í•™ìŠµ/ë¡œë“œ\n",
        "kor_model_path = f\"{KOR_TOKENIZER_PREFIX}.model\"\n",
        "eng_model_path = f\"{ENG_TOKENIZER_PREFIX}.model\"\n",
        "\n",
        "if os.path.exists(kor_model_path) and os.path.exists(eng_model_path):\n",
        "    print(\"ê¸°ì¡´ í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...\")\n",
        "else:\n",
        "    print(\"í† í¬ë‚˜ì´ì € í•™ìŠµ ì¤‘...\")\n",
        "    all_kor = train_ko + list(val_ko) + list(test_ko)\n",
        "    all_eng = train_en + list(val_en) + list(test_en)\n",
        "    train_sentencepiece(all_kor, KOR_TOKENIZER_PREFIX, DATA_CONFIG.vocab_size_kor)\n",
        "    train_sentencepiece(all_eng, ENG_TOKENIZER_PREFIX, DATA_CONFIG.vocab_size_eng)\n",
        "\n",
        "vocab_src = SentencePieceVocab(kor_model_path)\n",
        "vocab_trg = SentencePieceVocab(eng_model_path)\n",
        "\n",
        "print(f\"âœ… í•œêµ­ì–´ Vocab: {len(vocab_src):,}, ì˜ì–´ Vocab: {len(vocab_trg):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Dataset ë° DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_list, trg_list, vocab_src, vocab_trg, max_length=60):\n",
        "        self.src_list, self.trg_list = src_list, trg_list\n",
        "        self.vocab_src, self.vocab_trg = vocab_src, vocab_trg\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self): return len(self.src_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = [self.vocab_src.BOS_ID] + self.vocab_src.encode(self.src_list[idx]) + [self.vocab_src.EOS_ID]\n",
        "        trg = [self.vocab_trg.BOS_ID] + self.vocab_trg.encode(self.trg_list[idx]) + [self.vocab_trg.EOS_ID]\n",
        "        return {\n",
        "            'SRC': torch.tensor(src[:self.max_length], dtype=torch.long),\n",
        "            'TRG': torch.tensor(trg[:self.max_length], dtype=torch.long),\n",
        "            'SRC_TEXT': self.src_list[idx], 'TRG_TEXT': self.trg_list[idx]\n",
        "        }\n",
        "\n",
        "def collate_fn(batch, pad_idx=0):\n",
        "    src = pad_sequence([item['SRC'] for item in batch], batch_first=True, padding_value=pad_idx)\n",
        "    trg = pad_sequence([item['TRG'] for item in batch], batch_first=True, padding_value=pad_idx)\n",
        "    return {'SRC': src, 'TRG': trg, 'SRC_TEXT': [item['SRC_TEXT'] for item in batch], 'TRG_TEXT': [item['TRG_TEXT'] for item in batch]}\n",
        "\n",
        "# DataLoader ìƒì„±\n",
        "train_dataset = TranslationDataset(train_ko, train_en, vocab_src, vocab_trg, DATA_CONFIG.max_length)\n",
        "val_dataset = TranslationDataset(list(val_ko), list(val_en), vocab_src, vocab_trg, DATA_CONFIG.max_length)\n",
        "test_dataset = TranslationDataset(list(test_ko), list(test_en), vocab_src, vocab_trg, DATA_CONFIG.max_length)\n",
        "\n",
        "collate_with_pad = lambda batch: collate_fn(batch, pad_idx=vocab_src.PAD_ID)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=DATA_CONFIG.batch_size, shuffle=True, collate_fn=collate_with_pad)\n",
        "val_loader = DataLoader(val_dataset, batch_size=DATA_CONFIG.batch_size, shuffle=False, collate_fn=collate_with_pad)\n",
        "test_loader = DataLoader(test_dataset, batch_size=DATA_CONFIG.batch_size, shuffle=False, collate_fn=collate_with_pad)\n",
        "\n",
        "print(f\"âœ… DataLoader: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)} batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Transformer ëª¨ë¸ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.0, bias=False, encoder_decoder_attention=False, causal=False):\n",
        "        super().__init__()\n",
        "        self.emb_dim, self.num_heads = emb_dim, num_heads\n",
        "        self.dropout, self.head_dim = dropout, emb_dim // num_heads\n",
        "        self.encoder_decoder_attention, self.causal = encoder_decoder_attention, causal\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        return x.view(*x.size()[:-1], self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, query, key, attention_mask=None):\n",
        "        q = self.transpose_for_scores(self.q_proj(query))\n",
        "        k = self.transpose_for_scores(self.k_proj(key if self.encoder_decoder_attention else query))\n",
        "        v = self.transpose_for_scores(self.v_proj(key if self.encoder_decoder_attention else query))\n",
        "        \n",
        "        attn_weights = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
        "        if attention_mask is not None:\n",
        "            if self.causal:\n",
        "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
        "            else:\n",
        "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
        "        \n",
        "        attn_probs = F.dropout(F.softmax(attn_weights, dim=-1), p=self.dropout, training=self.training)\n",
        "        attn_output = torch.matmul(attn_probs, v).permute(0, 2, 1, 3).contiguous()\n",
        "        return self.out_proj(attn_output.view(*attn_output.size()[:-2], self.emb_dim)), attn_weights\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, emb_dim, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.w_1, self.w_2 = nn.Linear(emb_dim, d_ff), nn.Linear(d_ff, emb_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.dropout(self.w_2(F.dropout(F.relu(self.w_1(x)), p=self.dropout, training=self.training)), p=self.dropout, training=self.training)\n",
        "\n",
        "\n",
        "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
        "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
        "        super().__init__(num_positions, embedding_dim)\n",
        "        position_enc = torch.zeros(num_positions, embedding_dim)\n",
        "        for pos in range(num_positions):\n",
        "            for i in range(0, embedding_dim, 2):\n",
        "                position_enc[pos, i] = math.sin(pos / (10000 ** (i / embedding_dim)))\n",
        "                if i + 1 < embedding_dim:\n",
        "                    position_enc[pos, i + 1] = math.cos(pos / (10000 ** ((i + 1) / embedding_dim)))\n",
        "        self.weight.data.copy_(position_enc)\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, input_ids):\n",
        "        return super().forward(torch.arange(input_ids.size(1), device=self.weight.device))\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(config.emb_dim, config.num_heads, config.attention_dropout)\n",
        "        self.ffn = PositionWiseFeedForward(config.emb_dim, config.ffn_dim, config.dropout)\n",
        "        self.norm1, self.norm2 = nn.LayerNorm(config.emb_dim), nn.LayerNorm(config.emb_dim)\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_out, attn_weights = self.self_attn(self.norm1(x), self.norm1(x), mask)\n",
        "        x = x + F.dropout(attn_out, p=self.dropout, training=self.training)\n",
        "        x = x + F.dropout(self.ffn(self.norm2(x)), p=self.dropout, training=self.training)\n",
        "        return x, attn_weights\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(config.emb_dim, config.num_heads, config.attention_dropout, causal=True)\n",
        "        self.cross_attn = MultiHeadAttention(config.emb_dim, config.num_heads, config.attention_dropout, encoder_decoder_attention=True)\n",
        "        self.ffn = PositionWiseFeedForward(config.emb_dim, config.ffn_dim, config.dropout)\n",
        "        self.norm1, self.norm2, self.norm3 = nn.LayerNorm(config.emb_dim), nn.LayerNorm(config.emb_dim), nn.LayerNorm(config.emb_dim)\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "    def forward(self, x, enc_out, enc_mask=None, dec_mask=None):\n",
        "        self_attn_out, self_attn_w = self.self_attn(self.norm1(x), self.norm1(x), dec_mask)\n",
        "        x = x + F.dropout(self_attn_out, p=self.dropout, training=self.training)\n",
        "        cross_attn_out, cross_attn_w = self.cross_attn(self.norm2(x), enc_out, enc_mask)\n",
        "        x = x + F.dropout(cross_attn_out, p=self.dropout, training=self.training)\n",
        "        x = x + F.dropout(self.ffn(self.norm3(x)), p=self.dropout, training=self.training)\n",
        "        return x, (self_attn_w, cross_attn_w)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__()\n",
        "        self.embed_tokens = embed_tokens\n",
        "        self.embed_positions = SinusoidalPositionalEmbedding(config.max_position_embeddings, config.emb_dim)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.final_norm = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "    def forward(self, input_ids, mask=None):\n",
        "        x = self.dropout(self.embed_tokens(input_ids) + self.embed_positions(input_ids))\n",
        "        attn_scores = []\n",
        "        for layer in self.layers:\n",
        "            x, attn = layer(x, mask)\n",
        "            attn_scores.append(attn)\n",
        "        return self.final_norm(x), attn_scores\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__()\n",
        "        self.embed_tokens = embed_tokens\n",
        "        self.embed_positions = SinusoidalPositionalEmbedding(config.max_position_embeddings, config.emb_dim)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.final_norm = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "    def forward(self, input_ids, enc_out, enc_mask=None, dec_mask=None):\n",
        "        x = self.dropout(self.embed_tokens(input_ids) + self.embed_positions(input_ids))\n",
        "        attn_scores = []\n",
        "        for layer in self.layers:\n",
        "            x, attn = layer(x, enc_out, enc_mask, dec_mask)\n",
        "            attn_scores.append(attn)\n",
        "        return self.final_norm(x), attn_scores\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_src, vocab_trg, config):\n",
        "        super().__init__()\n",
        "        self.vocab_src, self.vocab_trg, self.config = vocab_src, vocab_trg, config\n",
        "        self.enc_embedding = nn.Embedding(len(vocab_src), config.emb_dim, padding_idx=vocab_src.PAD_ID)\n",
        "        self.dec_embedding = nn.Embedding(len(vocab_trg), config.emb_dim, padding_idx=vocab_trg.PAD_ID)\n",
        "        self.encoder = Encoder(config, self.enc_embedding)\n",
        "        self.decoder = Decoder(config, self.dec_embedding)\n",
        "        self.prediction_head = nn.Linear(config.emb_dim, len(vocab_trg))\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        enc_mask = (src == self.vocab_src.PAD_ID)\n",
        "        dec_mask = torch.triu(torch.ones(trg.size(1), trg.size(1), dtype=torch.bool, device=trg.device), diagonal=1)\n",
        "        enc_out, enc_attn = self.encoder(src, enc_mask)\n",
        "        dec_out, dec_attn = self.decoder(trg, enc_out, enc_mask, dec_mask)\n",
        "        return self.prediction_head(dec_out), enc_attn, dec_attn\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"âœ… Transformer ëª¨ë¸ ì •ì˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. ì†ì‹¤ í•¨ìˆ˜ ë° â­ Warmup Scheduler (í•µì‹¬!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.1, dim=-1, ignore_index=None):\n",
        "        super().__init__()\n",
        "        self.confidence, self.smoothing = 1.0 - smoothing, smoothing\n",
        "        self.cls, self.dim, self.ignore_index = classes, dim, ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred).fill_(self.smoothing / (self.cls - 2))\n",
        "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
        "            if self.ignore_index is not None:\n",
        "                true_dist[:, self.ignore_index] = 0\n",
        "                mask = torch.nonzero(target == self.ignore_index)\n",
        "                if mask.dim() > 0: true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
        "\n",
        "\n",
        "class TransformerScheduler:\n",
        "    \"\"\"\n",
        "    â­ Attention Is All You Need ë…¼ë¬¸ì˜ Learning Rate Schedule\n",
        "    lr = d_model^(-0.5) * min(step^(-0.5), step * warmup_steps^(-1.5))\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
        "        self.optimizer = optimizer\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.step_num = 0\n",
        "        self.current_lr = 0\n",
        "        \n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        self.current_lr = (self.d_model ** -0.5) * min(self.step_num ** -0.5, self.step_num * (self.warmup_steps ** -1.5))\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.current_lr\n",
        "        return self.current_lr\n",
        "    \n",
        "    def get_last_lr(self):\n",
        "        return [self.current_lr]\n",
        "\n",
        "print(\"âœ… Loss ë° TransformerScheduler ì •ì˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch_improved(model, iterator, optimizer, scheduler, criterion, clip, device):\n",
        "    \"\"\"ê°œì„ ëœ í•™ìŠµ í•¨ìˆ˜ (Scheduler í¬í•¨)\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    progress_bar = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        src, trg = batch['SRC'].to(device), batch['TRG'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _, _ = model(src, trg[:, :-1])\n",
        "        output = output.contiguous().view(-1, output.shape[-1])\n",
        "        trg_out = trg[:, 1:].contiguous().view(-1)\n",
        "        \n",
        "        loss = criterion(output, trg_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        current_lr = scheduler.step()  # â­ ë§¤ ë°°ì¹˜ë§ˆë‹¤ LR ì—…ë°ì´íŠ¸\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=f\"{loss.item():.3f}\", lr=f\"{current_lr:.2e}\")\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            src, trg = batch['SRC'].to(device), batch['TRG'].to(device)\n",
        "            output, _, _ = model(src, trg[:, :-1])\n",
        "            output = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg_out = trg[:, 1:].contiguous().view(-1)\n",
        "            epoch_loss += criterion(output, trg_out).item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "print(\"âœ… í•™ìŠµ/í‰ê°€ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. ë²ˆì—­ í•¨ìˆ˜ (Greedy + Beam Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, model, vocab_src, vocab_trg, device, max_len=60, repetition_penalty=1.3, no_repeat_ngram=3):\n",
        "    \"\"\"Greedy ë²ˆì—­ + Repetition Penalty\"\"\"\n",
        "    model.eval()\n",
        "    tokens = [vocab_src.BOS_ID] + vocab_src.encode(sentence) + [vocab_src.EOS_ID]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_mask = (src_tensor == vocab_src.PAD_ID)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_out, _ = model.encoder(src_tensor, src_mask)\n",
        "        trg_indexes = [vocab_trg.BOS_ID]\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "            dec_mask = torch.triu(torch.ones(len(trg_indexes), len(trg_indexes), dtype=torch.bool, device=device), diagonal=1)\n",
        "            dec_out, dec_attn = model.decoder(trg_tensor, enc_out, src_mask, dec_mask)\n",
        "            logits = dec_out[:, -1, :]\n",
        "            \n",
        "            # Repetition Penalty\n",
        "            for prev in set(trg_indexes):\n",
        "                logits[0, prev] = logits[0, prev] / repetition_penalty if logits[0, prev] > 0 else logits[0, prev] * repetition_penalty\n",
        "            \n",
        "            # No Repeat N-gram\n",
        "            if no_repeat_ngram > 0 and len(trg_indexes) >= no_repeat_ngram:\n",
        "                prefix = tuple(trg_indexes[-(no_repeat_ngram-1):])\n",
        "                for j in range(len(trg_indexes) - no_repeat_ngram + 1):\n",
        "                    if tuple(trg_indexes[j:j+no_repeat_ngram-1]) == prefix:\n",
        "                        logits[0, trg_indexes[j+no_repeat_ngram-1]] = float('-inf')\n",
        "            \n",
        "            pred = logits.argmax(-1).item()\n",
        "            trg_indexes.append(pred)\n",
        "            if pred == vocab_trg.EOS_ID: break\n",
        "\n",
        "    return [vocab_trg.itos[i] for i in trg_indexes[1:]], dec_attn[-1][1].squeeze(0).cpu().numpy()\n",
        "\n",
        "\n",
        "def translate_beam_search(sentence, model, vocab_src, vocab_trg, device, beam_size=5, max_len=60, length_penalty=0.6):\n",
        "    \"\"\"Beam Search ë²ˆì—­ (ë” ì¢‹ì€ í’ˆì§ˆ)\"\"\"\n",
        "    model.eval()\n",
        "    tokens = [vocab_src.BOS_ID] + vocab_src.encode(sentence) + [vocab_src.EOS_ID]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_mask = (src_tensor == vocab_src.PAD_ID)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_out, _ = model.encoder(src_tensor, src_mask)\n",
        "        beams = [(0.0, [vocab_trg.BOS_ID])]\n",
        "        completed = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            candidates = []\n",
        "            for score, seq in beams:\n",
        "                if seq[-1] == vocab_trg.EOS_ID:\n",
        "                    completed.append((score / (len(seq) ** length_penalty), seq))\n",
        "                    continue\n",
        "                trg_tensor = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
        "                dec_mask = torch.triu(torch.ones(len(seq), len(seq), dtype=torch.bool, device=device), diagonal=1)\n",
        "                dec_out, _ = model.decoder(trg_tensor, enc_out, src_mask, dec_mask)\n",
        "                log_probs = F.log_softmax(dec_out[:, -1, :], dim=-1)\n",
        "                top_probs, top_ids = log_probs.topk(beam_size)\n",
        "                for prob, idx in zip(top_probs[0], top_ids[0]):\n",
        "                    candidates.append((score + prob.item(), seq + [idx.item()]))\n",
        "            beams = sorted(candidates, key=lambda x: x[0], reverse=True)[:beam_size]\n",
        "            if len(completed) >= beam_size: break\n",
        "\n",
        "        for s, seq in beams:\n",
        "            completed.append((s / (len(seq) ** length_penalty), seq))\n",
        "        best = max(completed, key=lambda x: x[0]) if completed else beams[0]\n",
        "\n",
        "    return [vocab_trg.itos[i] for i in best[1] if i != vocab_trg.BOS_ID]\n",
        "\n",
        "print(\"âœ… ë²ˆì—­ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. ğŸš€ ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ”§ ëª¨ë¸ ì´ˆê¸°í™” (ê°œì„ ëœ ì„¤ì •)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "model = Transformer(vocab_src, vocab_trg, MODEL_CONFIG).to(device)\n",
        "print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {model.count_parameters():,}\")\n",
        "print(f\"d_model: {MODEL_CONFIG.emb_dim}, ffn_dim: {MODEL_CONFIG.ffn_dim}\")\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì € (lr=0ìœ¼ë¡œ ì‹œì‘, Schedulerê°€ ê´€ë¦¬)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(), lr=0,\n",
        "    betas=TRAIN_CONFIG.betas, eps=TRAIN_CONFIG.eps, weight_decay=TRAIN_CONFIG.weight_decay\n",
        ")\n",
        "\n",
        "# â­ Warmup Scheduler\n",
        "scheduler = TransformerScheduler(optimizer, d_model=MODEL_CONFIG.emb_dim, warmup_steps=TRAIN_CONFIG.warmup_steps)\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜\n",
        "criterion = LabelSmoothingLoss(classes=len(vocab_trg), smoothing=TRAIN_CONFIG.label_smoothing, ignore_index=vocab_trg.PAD_ID).to(device)\n",
        "\n",
        "print(f\"Warmup Steps: {TRAIN_CONFIG.warmup_steps}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµ ì‹¤í–‰\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸš€ í•™ìŠµ ì‹œì‘!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_losses, val_losses, learning_rates = [], [], []\n",
        "best_valid_loss = float('inf')\n",
        "patience_counter = 0\n",
        "total_start_time = time.time()\n",
        "\n",
        "for epoch in range(TRAIN_CONFIG.num_epochs):\n",
        "    epoch_start = time.time()\n",
        "    \n",
        "    train_loss = train_epoch_improved(model, train_loader, optimizer, scheduler, criterion, TRAIN_CONFIG.clip, device)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "    \n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    learning_rates.append(current_lr)\n",
        "    \n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"[Epoch {epoch+1:02d}/{TRAIN_CONFIG.num_epochs}] Train: {train_loss:.4f} | Val: {val_loss:.4f} | PPL: {np.exp(val_loss):.2f} | LR: {current_lr:.2e} | {epoch_time/60:.1f}m\", end=\"\")\n",
        "    \n",
        "    if val_loss < best_valid_loss - TRAIN_CONFIG.min_delta:\n",
        "        best_valid_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'val_loss': val_loss, 'config': MODEL_CONFIG}, MODEL_SAVE_PATH)\n",
        "        print(\" âœ… Saved!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\" (patience: {patience_counter}/{TRAIN_CONFIG.patience})\")\n",
        "    \n",
        "    if patience_counter >= TRAIN_CONFIG.patience:\n",
        "        print(f\"\\nâš ï¸ Early Stopping at Epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"âœ… í•™ìŠµ ì™„ë£Œ! ì´ ì‹œê°„: {(time.time()-total_start_time)/60:.1f}ë¶„\")\n",
        "print(f\"Best Val Loss: {best_valid_loss:.4f}, PPL: {np.exp(best_valid_loss):.2f}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].plot(train_losses, label='Train', color='blue')\n",
        "axes[0].plot(val_losses, label='Val', color='red')\n",
        "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Loss'); axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot([np.exp(l) for l in train_losses], label='Train', color='blue')\n",
        "axes[1].plot([np.exp(l) for l in val_losses], label='Val', color='red')\n",
        "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Perplexity')\n",
        "axes[1].set_title('Perplexity'); axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(learning_rates, color='green')\n",
        "axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('LR')\n",
        "axes[2].set_title('Learning Rate (Warmup)'); axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{MODEL_DIR}/training_curves.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14. ë²ˆì—­ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best ëª¨ë¸ ë¡œë“œ\n",
        "checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ”¤ ë²ˆì—­ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_sentences = [\n",
        "    \"ë¶í•œì´ ë¯¸ì‚¬ì¼ì„ ë°œì‚¬í–ˆë‹¤.\",\n",
        "    \"ëŒ€í†µë ¹ì´ ê¸°ìíšŒê²¬ì„ ì—´ì—ˆë‹¤.\",\n",
        "    \"ì£¼ì‹ ì‹œì¥ì´ í•˜ë½í–ˆë‹¤.\",\n",
        "    \"ë¯¸êµ­ê³¼ ì¤‘êµ­ì˜ ë¬´ì—­ ì „ìŸì´ ê³„ì†ë˜ê³  ìˆë‹¤.\",\n",
        "]\n",
        "\n",
        "for i, sent in enumerate(test_sentences, 1):\n",
        "    print(f\"\\n[{i}] ì›ë¬¸: {sent}\")\n",
        "    \n",
        "    greedy, _ = translate_sentence(sent, model, vocab_src, vocab_trg, device)\n",
        "    greedy_text = ''.join([t for t in greedy if t not in ['<eos>','</s>']]).replace('â–', ' ').strip()\n",
        "    print(f\"    Greedy: {greedy_text}\")\n",
        "    \n",
        "    beam = translate_beam_search(sent, model, vocab_src, vocab_trg, device, beam_size=5)\n",
        "    beam_text = ''.join([t for t in beam if t not in ['<eos>','</s>']]).replace('â–', ' ').strip()\n",
        "    print(f\"    Beam:   {beam_text}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… ë²ˆì—­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ì…‹ ìƒ˜í”Œ ë²ˆì—­\n",
        "print(\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸ì…‹ ìƒ˜í”Œ\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for i in range(5):\n",
        "    src = test_dataset.src_list[i]\n",
        "    trg = test_dataset.trg_list[i]\n",
        "    beam = translate_beam_search(src, model, vocab_src, vocab_trg, device, beam_size=5)\n",
        "    pred = ''.join([t for t in beam if t not in ['<eos>','</s>']]).replace('â–', ' ').strip()\n",
        "    \n",
        "    print(f\"\\n[{i+1}]\")\n",
        "    print(f\"  ì›ë¬¸: {src[:60]}...\")\n",
        "    print(f\"  ì •ë‹µ: {trg[:60]}...\")\n",
        "    print(f\"  ì˜ˆì¸¡: {pred[:60]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# âœ… ì™„ë£Œ!\n",
        "\n",
        "## ê°œì„  íš¨ê³¼ ìš”ì•½\n",
        "\n",
        "| ì§€í‘œ | ê¸°ì¡´ | ê°œì„  í›„ |\n",
        "|------|------|--------|\n",
        "| Val Loss | ~2.93 | **< 2.0** (ì˜ˆìƒ) |\n",
        "| Perplexity | ~18.7 | **< 8** (ì˜ˆìƒ) |\n",
        "| ë²ˆì—­ í’ˆì§ˆ | ì˜ë¯¸ ì—†ìŒ | **ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥** |\n",
        "\n",
        "í•µì‹¬ ê°œì„ : **Warmup Learning Rate Scheduler**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {"gpuType": "T4", "provenance": []},
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"name": "python", "version": "3.10.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
