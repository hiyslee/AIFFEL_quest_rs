{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Z42N6Kxmka",
        "outputId": "8d57467b-1417-4e3a-dc16-5ebf9b481aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 4.39 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (1.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2025-11-13 18:03:50--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.26, 104.192.142.25, 104.192.142.24, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIG6NQOQ6&Signature=aPJjCFTOn3zHLamLZx6M7dMMTuw%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQC0FoN75LyOkCf7g0fIe2vqLwP%2B7BMEpyF7VElNtCkMpwIhAP83Ru8XVYHpoRyTLn4Tp05OvnaMHCzqNdAgsZko5EGMKqcCCFMQABoMOTg0NTI1MTAxMTQ2IgyJllKcMx5xvOhJ200qhAIL97w2PwrbUFUwupWssJkEIDndsb6Ot%2BI1a8JB9n06pMmCVoxHSXmEGLDkzumW6%2FVaovBVU6Ped3aYxP%2F8Fu5lcZd3SyZQsUoD6eZMsiYsSpo8zwyL7aPoqkxpwiDxhBLgXbTjiM%2Blhulh51oBMVQQEPPkU2Qclywhe0FkhbAmfwPDjjUzW2ODb9RtjNkXu0JyrG6ii6t7GC4SXTtcqnDadu8xmrPV2pGa1gXD3RktOYs%2BbRR0hh2rDFK1dEAKcHwaMBbPOLVWShEBXGiIpVt9J1%2B7tP1SdsVlZW3ZSr4fmc%2FH4HjFOrENIx4jJ9wB%2B5FJtorV6wmv8eHIQi0v3%2Fx5xW%2B9wjCGu9jIBjqcAZKyO%2B0g0AeseAe3yIzPbKK8FLaRbQG1DKBT2qdMqaCdzxjKi2U3gkkxu55zHpCurP6LNXl7qssFuLB3i6H8lyRBsbUYIjbck%2F2XUDF3NQ%2BhDqF6YBSfHIgmvZhPw244ouSZx%2BjGO2S9wuH%2FiachzE4vy1UMQE82uZQ2r2A8O8O5xeT3Y8JfleHz58KUhkppVe4MVpW4KJD77f3c9w%3D%3D&Expires=1763058830 [following]\n",
            "--2025-11-13 18:03:50--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIG6NQOQ6&Signature=aPJjCFTOn3zHLamLZx6M7dMMTuw%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQC0FoN75LyOkCf7g0fIe2vqLwP%2B7BMEpyF7VElNtCkMpwIhAP83Ru8XVYHpoRyTLn4Tp05OvnaMHCzqNdAgsZko5EGMKqcCCFMQABoMOTg0NTI1MTAxMTQ2IgyJllKcMx5xvOhJ200qhAIL97w2PwrbUFUwupWssJkEIDndsb6Ot%2BI1a8JB9n06pMmCVoxHSXmEGLDkzumW6%2FVaovBVU6Ped3aYxP%2F8Fu5lcZd3SyZQsUoD6eZMsiYsSpo8zwyL7aPoqkxpwiDxhBLgXbTjiM%2Blhulh51oBMVQQEPPkU2Qclywhe0FkhbAmfwPDjjUzW2ODb9RtjNkXu0JyrG6ii6t7GC4SXTtcqnDadu8xmrPV2pGa1gXD3RktOYs%2BbRR0hh2rDFK1dEAKcHwaMBbPOLVWShEBXGiIpVt9J1%2B7tP1SdsVlZW3ZSr4fmc%2FH4HjFOrENIx4jJ9wB%2B5FJtorV6wmv8eHIQi0v3%2Fx5xW%2B9wjCGu9jIBjqcAZKyO%2B0g0AeseAe3yIzPbKK8FLaRbQG1DKBT2qdMqaCdzxjKi2U3gkkxu55zHpCurP6LNXl7qssFuLB3i6H8lyRBsbUYIjbck%2F2XUDF3NQ%2BhDqF6YBSfHIgmvZhPw244ouSZx%2BjGO2S9wuH%2FiachzE4vy1UMQE82uZQ2r2A8O8O5xeT3Y8JfleHz58KUhkppVe4MVpW4KJD77f3c9w%3D%3D&Expires=1763058830\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.203.97, 52.216.48.49, 52.217.224.25, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.203.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  4.12MB/s    in 0.3s    \n",
            "\n",
            "2025-11-13 18:03:51 (4.12 MB/s) - â€˜mecab-0.996-ko-0.9.2.tar.gzâ€™ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2025-11-13 18:05:26--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.24, 104.192.142.25, 104.192.142.26, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNELEZWMEZ&Signature=6a4dq1F%2BFEhp4dz2RZ%2F9nlvK5fs%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQC06sifoHKguxE3EK4oj0ImiX7oNTj3xzKqadnYG9zOhAIhAIPWbXfzQOgh%2Fjc1a0g%2BgSDUfBIZwtf7FGG0eFElWybaKqcCCFMQABoMOTg0NTI1MTAxMTQ2IgwBp%2Brz490%2FfXpqnm8qhAI1YiTZ7kTuWN9hDdiwq2xkMZ4v122CNa0skCNLq1kvX%2F4vlH48nkExP%2Ft6sChNuYejfIERa0oE5pGCShmamxBMhyZ0MKFfGskXmak9Iz%2FOPestgEcMJm9Xaernm2bo6nOp4TlfeDzh5JVy0wo%2BywLJLp%2F67w%2FWMsLNZN8WatBUJ6C2IkQ4H93ArjYnIeJo%2B1YfZFhrbZuYngkhVY4rBzDpRMgZv9xZwh%2BlIcIZ4lmqMf6cHwqKhJWuJEXCKAWJYUifrqqFkAZIXokeMlV5db%2BE8fnqY6oXq%2FffX8UCNQnNxT4xmDhdIvFqqaHiFzj9%2FtkVr69x305LNPTlg33yDYqYBD%2Fu5zDgu9jIBjqcAUed16OCefuU5GWWr3nfBmKTZYnUNtOnR0iq8X6r1rErYOXrvruvwgcQcDf26ooe9CbizIOuiIPACeQGVkxM3cvDpFnCTO0ZPBdmyhb1rFUBmt17VyT9yBoS5dCGKDBxlPW3HnWCzA8HkAePNt9NpMlMjHjMScvTWfez6Mk4PjvfmRj%2BVvYIeT4er8uPAtkVNDi61dJwroVcvuahBA%3D%3D&Expires=1763058920 [following]\n",
            "--2025-11-13 18:05:26--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNELEZWMEZ&Signature=6a4dq1F%2BFEhp4dz2RZ%2F9nlvK5fs%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQC06sifoHKguxE3EK4oj0ImiX7oNTj3xzKqadnYG9zOhAIhAIPWbXfzQOgh%2Fjc1a0g%2BgSDUfBIZwtf7FGG0eFElWybaKqcCCFMQABoMOTg0NTI1MTAxMTQ2IgwBp%2Brz490%2FfXpqnm8qhAI1YiTZ7kTuWN9hDdiwq2xkMZ4v122CNa0skCNLq1kvX%2F4vlH48nkExP%2Ft6sChNuYejfIERa0oE5pGCShmamxBMhyZ0MKFfGskXmak9Iz%2FOPestgEcMJm9Xaernm2bo6nOp4TlfeDzh5JVy0wo%2BywLJLp%2F67w%2FWMsLNZN8WatBUJ6C2IkQ4H93ArjYnIeJo%2B1YfZFhrbZuYngkhVY4rBzDpRMgZv9xZwh%2BlIcIZ4lmqMf6cHwqKhJWuJEXCKAWJYUifrqqFkAZIXokeMlV5db%2BE8fnqY6oXq%2FffX8UCNQnNxT4xmDhdIvFqqaHiFzj9%2FtkVr69x305LNPTlg33yDYqYBD%2Fu5zDgu9jIBjqcAUed16OCefuU5GWWr3nfBmKTZYnUNtOnR0iq8X6r1rErYOXrvruvwgcQcDf26ooe9CbizIOuiIPACeQGVkxM3cvDpFnCTO0ZPBdmyhb1rFUBmt17VyT9yBoS5dCGKDBxlPW3HnWCzA8HkAePNt9NpMlMjHjMScvTWfez6Mk4PjvfmRj%2BVvYIeT4er8uPAtkVNDi61dJwroVcvuahBA%3D%3D&Expires=1763058920\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.15.201.184, 16.15.177.205, 16.15.181.127, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.15.201.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  31.6MB/s    in 1.5s    \n",
            "\n",
            "2025-11-13 18:05:28 (31.6 MB/s) - â€˜mecab-ko-dic-2.1.1-20180720.tar.gzâ€™ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "ì‚¬ìš©ì ì‚¬ì „ ì¶”ê°€ ë°©ë²• : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŸ°íƒ€ì„ì„ ì¬ì‹¤í–‰ í•´ì£¼ì„¸ìš”\n",
            "ë¸”ë¡œê·¸ì— í•´ê²° ë°©ë²•ì„ ë‚¨ê²¨ì£¼ì‹  tanaë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
            "light ë²„ì „ ì‘ì„± : Dogdriipë‹˜ ( https://github.com/Dogdriip )\n",
            "ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì‹  combacsaë‹˜ ê°ì‚¬í•©ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¹ ë‹¤ ëª¨ì•„ë´¤ìŠµë‹ˆë‹¤.\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import konlpy\n",
        "\n",
        "# â­â­â­ [NEW] MECAB ì„í¬íŠ¸ ì¶”ê°€ â­â­â­\n",
        "from konlpy.tag import Mecab\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "# â­â­â­ [END NEW] â­â­â­\n",
        "\n",
        "print(torch.__version__)\n",
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(matplotlib.__version__)\n",
        "print(konlpy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfKE4aJUlo1D",
        "outputId": "1be5b28e-5cb4-45a0-813f-3ef89278713d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "2.0.2\n",
            "2.2.2\n",
            "3.10.0\n",
            "0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°ì´í„° ì—…ë¡œë“œ!"
      ],
      "metadata": {
        "id": "9Kl7K9k1aIh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_table(\"/content/ratings_train.txt\")\n",
        "test = pd.read_table(\"/content/ratings_test.txt\")\n",
        "\n",
        "print(train.info())\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "BD0Qt16LUzs6",
        "outputId": "60f42b5d-3465-446b-e567-62963d9e8ab9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150000 entries, 0 to 149999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        150000 non-null  int64 \n",
            " 1   document  149995 non-null  object\n",
            " 2   label     150000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.4+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                ì•„ ë”ë¹™.. ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬      0\n",
              "1   3819312                  í ...í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„....ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜      1\n",
              "2  10265843                                  ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤      0\n",
              "3   9045019                      êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ ..ì†”ì§íˆ ì¬ë¯¸ëŠ” ì—†ë‹¤..í‰ì  ì¡°ì •      0\n",
              "4   6483659  ì‚¬ì´ëª¬í˜ê·¸ì˜ ìµì‚´ìŠ¤ëŸ° ì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ì˜í™”!ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71d4b3d6-753a-45ac-aa39-4344fd416952\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>ì•„ ë”ë¹™.. ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>í ...í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„....ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ ..ì†”ì§íˆ ì¬ë¯¸ëŠ” ì—†ë‹¤..í‰ì  ì¡°ì •</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>ì‚¬ì´ëª¬í˜ê·¸ì˜ ìµì‚´ìŠ¤ëŸ° ì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ì˜í™”!ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71d4b3d6-753a-45ac-aa39-4344fd416952')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71d4b3d6-753a-45ac-aa39-4344fd416952 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71d4b3d6-753a-45ac-aa39-4344fd416952');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-400e6cbd-28a5-4310-b80a-098fd09023cc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-400e6cbd-28a5-4310-b80a-098fd09023cc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-400e6cbd-28a5-4310-b80a-098fd09023cc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„° ì—…ë¡œë”© ì•ˆí•˜ë©´ ì•ˆë©ë‹ˆë‹¤!! ã…œ ë‹¤ìŒ ë¸”ëŸ­ ì‹œì‘ì „ì—.. ë‚˜ëŠ”ì•¼ ì½”ë© ìœ ì €.."
      ],
      "metadata": {
        "id": "iV0_AeNumYI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 2: ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "train = pd.read_table(\"/content/ratings_train.txt\")\n",
        "test = pd.read_table(\"/content/ratings_test.txt\")\n",
        "\n",
        "print(train.info())\n",
        "train.head()\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 4: í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "import re\n",
        "\n",
        "# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸\n",
        "STOPWORDS = ['ì˜','ê°€','ì´','ì€','ë“¤','ëŠ”','ì¢€','ì˜','ê±','ê³¼','ë„','ë¥¼','ìœ¼ë¡œ','ì','ì—','ì™€','í•œ','í•˜ë‹¤']\n",
        "\n",
        "# ë§ì¶¤ë²• ë³€í˜• ì‚¬ì „\n",
        "SPELLING_DICT = {\n",
        "    'êµ³': ['ê¶…', 'êµ³', 'êµ¿'],\n",
        "    'ë¯¸ì³¤': ['ë¯¸ì²«', 'ë¯¸ì³£', 'ë¯¸ì²¬', 'ë¯¸ì³¤', 'ã…ã…Š'],\n",
        "    'ê´œì°®': ['ê´œì°®', 'ê´œì¶˜', 'ê´œì°¬', 'ã„±ã…Š', 'ê° ì°¬', 'ê° ì°®', 'ê´¸ì°¬', 'ê´¸ì°®'],\n",
        "    'ë´¤': ['ë´£'],\n",
        "    'ê² ': ['ê²Ÿ']\n",
        "}\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…\n",
        "TEXT_COL = \"document\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = str(text)\n",
        "\n",
        "    # 1. ë°˜ë³µë˜ëŠ” ë¬¸ì¥ ë¶€í˜¸ ì œê±° (2ê°œ ì´ìƒ â†’ 1ê°œ)\n",
        "    text = re.sub(r'([.!?â€¦;])\\1+', r'\\1', text)\n",
        "\n",
        "    # 2. ë§ì¶¤ë²• ë³€í˜• í†µì¼\n",
        "    for correct, variations in SPELLING_DICT.items():\n",
        "        for variant in variations:\n",
        "            text = text.replace(variant, correct)\n",
        "\n",
        "    # 3. ë°˜ë³µ ë¬¸ì ì œê±° (3ë²ˆ ì´ìƒ ë°˜ë³µ â†’ 2ë²ˆ)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "\n",
        "    # 4. ììŒ/ëª¨ìŒ ë‹¨ë… ì œê±°\n",
        "    text = re.sub(r'[ã„±-ã…ã…-ã…£]+', ' ', text)\n",
        "\n",
        "    # 5. ì˜ì–´/ìˆ«ì/í•œê¸€/ë¬¸ì¥ë¶€í˜¸ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì‚­ì œ\n",
        "    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s.!?,]', ' ', text)\n",
        "\n",
        "    # 6. ë¬¸ì¥ë¶€í˜¸ ì•ë’¤ë¡œ ê³µë°± ì¶”ê°€\n",
        "    text = re.sub(r'([.!?,])', r' \\1 ', text)\n",
        "\n",
        "    # 7. ì˜ì–´ ì†Œë¬¸ì ë³€í™˜\n",
        "    text = text.lower()\n",
        "\n",
        "    # 8. ë¶ˆìš©ì–´ ì œê±° (ì¡°ì‚¬ê°€ ë¶™ì€ ê²½ìš°ë„ ì²˜ë¦¬)\n",
        "    words = text.split()\n",
        "\n",
        "    # ë‹¨ì–´ ëì— ë¶ˆìš©ì–´ê°€ ë¶™ì–´ìˆìœ¼ë©´ ì œê±°\n",
        "    filtered_words = []\n",
        "    for word in words:\n",
        "        # ë‹¨ì–´ ì „ì²´ê°€ ë¶ˆìš©ì–´ì¸ ê²½ìš°\n",
        "        if word in STOPWORDS:\n",
        "            continue\n",
        "        # ë‹¨ì–´ ëì—ì„œ ë¶ˆìš©ì–´ ì œê±° (ê°€ì¥ ê¸´ ê²ƒë¶€í„° ì²´í¬)\n",
        "        found = False\n",
        "        for stopword in sorted(STOPWORDS, key=len, reverse=True):\n",
        "            if len(word) > len(stopword) and word.endswith(stopword):\n",
        "                cleaned = word[:-len(stopword)]\n",
        "                if len(cleaned) >= 2:\n",
        "                    filtered_words.append(cleaned)\n",
        "                    found = True\n",
        "                    break\n",
        "        if not found:\n",
        "            filtered_words.append(word)\n",
        "\n",
        "    text = ' '.join(filtered_words)\n",
        "\n",
        "    # 9. ì—°ì† ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ êµì²´\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # 10. ì•ë’¤ ê³µë°± ì œê±°\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocess_dataframe(df, text_col=TEXT_COL):\n",
        "    \"\"\"\n",
        "    ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    print(f\"ì „ì²˜ë¦¬ ì „ ë°ì´í„° í¬ê¸°: {len(df)}\")\n",
        "\n",
        "    # 1. ê²°ì¸¡ì¹˜ ì œê±°\n",
        "    df = df.dropna(subset=[text_col])\n",
        "    print(f\"ê²°ì¸¡ì¹˜ ì œê±° í›„: {len(df)}\")\n",
        "\n",
        "    # 2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì ìš©\n",
        "    df[text_col] = df[text_col].apply(preprocess_text)\n",
        "\n",
        "    # 3. ì „ì²˜ë¦¬ í›„ ë¹ˆ ë¬¸ìì—´ ì œê±°\n",
        "    df = df[df[text_col].str.strip() != '']\n",
        "    print(f\"ë¹ˆ ë¬¸ìì—´ ì œê±° í›„: {len(df)}\")\n",
        "\n",
        "    # 4. ì¤‘ë³µ í–‰ ì œê±°\n",
        "    df = df.drop_duplicates(subset=[text_col])\n",
        "    print(f\"ì¤‘ë³µ ì œê±° í›„: {len(df)}\")\n",
        "\n",
        "    # ì¸ë±ìŠ¤ ì¬ì„¤ì •\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸\n",
        "sample_texts = [\n",
        "    \"ì–´ì œ ë³¸ ì˜í™” ì§„ì§œ ì¬ë°Œì—ˆìŒ!!! ë˜ ë³´ê³  ì‹¶ì–´ ğŸ˜‚\",\n",
        "    \"ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ì— í•™êµì— ê°”ë‹¤. ê·¼ë° ë„ˆë¬´ ì¡¸ë ¸ìŒã…‹ã…‹ã…‹ã…‹\",\n",
        "    \"ë°¥ì€ ë¨¹ì—ˆë‹ˆ?? ì•„ì§ì´ì•¼... ì ì‹¬ì— ê°™ì´ ë¨¹ì!!!\",\n",
        "    \"ë©”ìº… í˜•íƒœì†Œ ë¶„ì„ì€ í•œêµ­ì–´ ì²˜ë¦¬ì—ì„œ ë§ì´ ì‚¬ìš©ë¼ ğŸ‘\",\n",
        "    \"íŒŒì´ì¬ìœ¼ë¡œ í† í° ë¹ˆë„ì™€ í’ˆì‚¬ ë¶„í¬ë¥¼ ì‹œê°í™”í•´ ë³´ì!!!\",\n",
        "    \"ìš”ì¦˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ RG êµ¬ì¶•ì„ ë§ì´ í•´!!\",\n",
        "    \"ì—ì´ì „íŠ¸ëŠ” ì™¸ë¶€ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ ì‘ì—…ì„ ìë™í™”í•  ìˆ˜ ìˆì–´. êµ³!\",\n",
        "    \"ì´ ì˜í™” ì§„ì§œ ë¯¸ì³£ë‹¤!!! ë„ˆë¬´ ì¬ë°ŒìŒã…‹ã…‹ã…‹ã…‹\",\n",
        "    \"ë°°ìš° ì—°ê¸° êµ³ì´ í›Œë¥­í–ˆìŒ, ìŠ¤í† ë¦¬ëŠ” ë´£ì§€ë§Œ...\",\n",
        "    \"ì´ê±´ ã„±ã…Š ì˜í™”ë„¤, êµ¿êµ¿!\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê²°ê³¼\")\n",
        "print(\"=\" * 80)\n",
        "for i, text in enumerate(sample_texts, 1):\n",
        "    processed = preprocess_text(text)\n",
        "    print(f\"\\n[{i}] ì›ë³¸: {text}\")\n",
        "    print(f\"    ê²°ê³¼: {processed}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ì‹¤ì œ ë°ì´í„° ì ìš© ì˜ˆì‹œ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "train_processed = preprocess_dataframe(train.copy())\n",
        "test_processed = preprocess_dataframe(test.copy())\n",
        "\n",
        "print(\"\\nì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "print(f\"Train ë°ì´í„°: {len(train_processed)}ê°œ\")\n",
        "print(f\"Test ë°ì´í„°: {len(test_processed)}ê°œ\")\n",
        "\n",
        "print(\"\\nì „ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
        "print(train_processed.head(10))\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# â­â­â­ [NEW] ì…€ 4-1: MECAB í˜•íƒœì†Œ ë¶„ì„ ì¶”ê°€ â­â­â­\n",
        "# ================================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ”§ MECAB í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# MECAB ì´ˆê¸°í™”\n",
        "mecab = Mecab()\n",
        "print(\"âœ… MECAB ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "# MECAB ë™ì‘ í…ŒìŠ¤íŠ¸\n",
        "test_result = mecab.morphs(\"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ìˆì—ˆì–´\")\n",
        "print(f\"âœ… MECAB ì •ìƒ ì‘ë™\")\n",
        "print(f\"ë¶„ì„ ê²°ê³¼: {test_result}\")\n",
        "\n",
        "\n",
        "def mecab_morphs_analysis(text):\n",
        "    \"\"\"\n",
        "    MECAB í˜•íƒœì†Œ ë¶„ì„ í•¨ìˆ˜\n",
        "    - ì…ë ¥: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸\n",
        "    - ì¶œë ¥: í˜•íƒœì†Œ ë¦¬ìŠ¤íŠ¸ (ê³µë°±ìœ¼ë¡œ ê²°í•©)\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or text.strip() == '':\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        morphs = mecab.morphs(text)\n",
        "        return ' '.join(morphs)\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "\n",
        "def apply_mecab_to_dataframe(df, text_col=TEXT_COL):\n",
        "    \"\"\"\n",
        "    ë°ì´í„°í”„ë ˆì„ì— MECAB í˜•íƒœì†Œ ë¶„ì„ ì ìš©\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ”„ MECAB í˜•íƒœì†Œ ë¶„ì„ ì²˜ë¦¬ ì¤‘...\")\n",
        "    df['document_morphs'] = df[text_col].apply(\n",
        "        lambda x: mecab_morphs_analysis(x) if pd.notna(x) else \"\"\n",
        "    )\n",
        "\n",
        "    # ë¶„ì„ ê²°ê³¼ ìƒ˜í”Œ í‘œì‹œ\n",
        "    print(f\"\\nğŸ“Š MECAB ë¶„ì„ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
        "    print(\"=\" * 100)\n",
        "    for i in range(min(3, len(df))):\n",
        "        print(f\"\\n[ìƒ˜í”Œ {i+1}]\")\n",
        "        print(f\"  ì›ë³¸:      {df[text_col].iloc[i][:80]}\")\n",
        "        print(f\"  í˜•íƒœì†Œ:    {df['document_morphs'].iloc[i][:80]}\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Train/Test ë°ì´í„°ì— MECAB ë¶„ì„ ì ìš©\n",
        "train_processed = apply_mecab_to_dataframe(train_processed)\n",
        "test_processed = apply_mecab_to_dataframe(test_processed)\n",
        "\n",
        "print(f\"\\nâœ… MECAB í˜•íƒœì†Œ ë¶„ì„ ì™„ë£Œ!\")\n",
        "print(f\"   Train: {len(train_processed)}ê°œ ë¬¸ì¥ ë¶„ì„\")\n",
        "print(f\"   Test: {len(test_processed)}ê°œ ë¬¸ì¥ ë¶„ì„\")\n",
        "\n",
        "# â­â­â­ [END NEW] â­â­â­\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 6: SentencePiece ì„¤ì¹˜ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "!pip install sentencepiece\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 7: SentencePiece í•™ìŠµ (ìˆ˜ì •: MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©)\n",
        "# ================================================================================\n",
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "# í•™ìŠµìš© corpus íŒŒì¼ ìƒì„±\n",
        "corpus_file = 'naver_reviews.train.temp'\n",
        "\n",
        "# â­â­â­ [MODIFIED] ê¸°ì¡´: train_processed['document'] â†’ ìˆ˜ì •: train_processed['document_morphs'] â­â­â­\n",
        "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
        "    for text in train_processed['document_morphs']:  # ë³€ê²½: MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©\n",
        "        f.write(text + '\\n')\n",
        "# â­â­â­ [END MODIFIED] â­â­â­\n",
        "\n",
        "# SentencePiece í•™ìŠµ\n",
        "vocab_size = 8000\n",
        "model_prefix = 'naver_spm'\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    f'--input={corpus_file} '\n",
        "    f'--model_prefix={model_prefix} '\n",
        "    f'--vocab_size={vocab_size} '\n",
        "    f'--model_type=bpe '\n",
        "    f'--pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 '\n",
        "    f'--pad_piece=<PAD> --unk_piece=<UNK> --bos_piece=<BOS> --eos_piece=<EOS>'\n",
        ")\n",
        "\n",
        "!ls -l naver_spm*\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 8: SentencePiece í•™ìŠµëœ ëª¨ë¸ í™œìš© (ìˆ˜ì •: MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©)\n",
        "# ================================================================================\n",
        "# í•™ìŠµëœ SentencePiece ëª¨ë¸ í™œìš© ì˜ˆì‹œ\n",
        "sp = spm.SentencePieceProcessor(model_file=f'{model_prefix}.model')\n",
        "\n",
        "sample_text = \"ì´ ì˜í™” ì§„ì§œ ë¯¸ì³£ë‹¤!!! ë„ˆë¬´ ì¬ë°ŒìŒã…‹ã…‹ã…‹ã…‹\"\n",
        "\n",
        "# â­â­â­ [MODIFIED] MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ë¥¼ SentencePieceë¡œ ì¸ì½”ë”© â­â­â­\n",
        "sample_text_preprocessed = preprocess_text(sample_text)\n",
        "sample_text_morphs = mecab_morphs_analysis(sample_text_preprocessed)  # MECAB í˜•íƒœì†Œ ë¶„ì„\n",
        "\n",
        "encoded_ids = sp.encode(sample_text_morphs,  # ë³€ê²½: MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©\n",
        "                        out_type=int, add_bos=True, add_eos=True)\n",
        "# â­â­â­ [END MODIFIED] â­â­â­\n",
        "\n",
        "decoded_text = sp.decode(encoded_ids)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ğŸ“Š SentencePiece í† í°í™” ì˜ˆì‹œ (MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ì›ë³¸ í…ìŠ¤íŠ¸:       {sample_text}\")\n",
        "print(f\"ì •ê·œì‹ ì „ì²˜ë¦¬:     {sample_text_preprocessed}\")\n",
        "print(f\"MECAB í˜•íƒœì†Œ:      {sample_text_morphs}\")\n",
        "print(f\"Encoded IDs:       {encoded_ids}\")\n",
        "print(f\"Decoded Text:      {decoded_text}\")\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 12: SentencePiece í† í°í™” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "def sp_tokenize(s, corpus):\n",
        "\n",
        "    tensor = []\n",
        "\n",
        "    for sen in corpus:\n",
        "        tensor.append(torch.tensor(s.EncodeAsIds(sen), dtype=torch.long))\n",
        "\n",
        "    with open(\"./naver_spm.vocab\", 'r') as f:\n",
        "        vocab = f.readlines()\n",
        "\n",
        "    word_index = {}\n",
        "    index_word = {}\n",
        "\n",
        "    for idx, line in enumerate(vocab):\n",
        "        word = line.split(\"\\t\")[0]\n",
        "\n",
        "        word_index.update({word:idx})\n",
        "        index_word.update({idx:word})\n",
        "\n",
        "    tensor = pad_sequence(tensor, batch_first=True, padding_value=0)\n",
        "\n",
        "    return tensor, word_index, index_word\n",
        "\n",
        "\n",
        "# â­â­â­ [NEW] í† í°í™” ë° í…ì„œ ë³€í™˜ ì¶”ê°€ â­â­â­\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ“Š ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# PAD_IDXê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ë‹¤ì‹œ ì •ì˜\n",
        "PAD_IDX = 0 # ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…€ì— ìˆì§€ë§Œ, ì—¬ê¸°ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ í•¨ê»˜ ì •ì˜\n",
        "\n",
        "# í›ˆë ¨ ë°ì´í„° í† í°í™”\n",
        "train_input_ids, _, _ = sp_tokenize(sp, train_processed['document_morphs'])\n",
        "train_attention_masks = (train_input_ids != PAD_IDX).long()\n",
        "train_labels_tensor = torch.tensor(train_processed['label'].values, dtype=torch.float)\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í† í°í™”\n",
        "test_input_ids, _, _ = sp_tokenize(sp, test_processed['document_morphs'])\n",
        "test_attention_masks = (test_input_ids != PAD_IDX).long()\n",
        "test_labels_tensor = torch.tensor(test_processed['label'].values, dtype=torch.float)\n",
        "\n",
        "print(f\"âœ… í›ˆë ¨ ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜ ì™„ë£Œ. (Shape: {train_input_ids.shape})\")\n",
        "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜ ì™„ë£Œ. (Shape: {test_input_ids.shape})\")\n",
        "# â­â­â­ [END NEW] â­â­â­\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 15: DataLoader ìƒì„± (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "def create_dataloaders(train_input_ids, train_attention_masks, train_labels,\n",
        "                       test_input_ids, test_attention_masks, test_labels,\n",
        "                       batch_size=32, val_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Train/Val/Test DataLoader ìƒì„±\n",
        "\n",
        "    Args:\n",
        "        train_input_ids: í›ˆë ¨ ë°ì´í„° ì…ë ¥ ID í…ì„œ\n",
        "        train_attention_masks: í›ˆë ¨ ë°ì´í„° ì–´í…ì…˜ ë§ˆìŠ¤í¬ í…ì„œ\n",
        "        train_labels: í›ˆë ¨ ë ˆì´ë¸”\n",
        "        test_input_ids: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥ ID í…ì„œ\n",
        "        test_attention_masks: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì–´í…ì…˜ ë§ˆìŠ¤í¬ í…ì„œ\n",
        "        test_labels: í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”\n",
        "        batch_size: ë°°ì¹˜ í¬ê¸°\n",
        "        val_ratio: validation ë¹„ìœ¨\n",
        "\n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    # Train ë°ì´í„°ì—ì„œ train/val split\n",
        "    train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "    val_size = int(len(train_dataset) * val_ratio)\n",
        "    train_size = len(train_dataset) - val_size\n",
        "    train_split, val_split = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # DataLoader ìƒì„±\n",
        "    train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Test DataLoader\n",
        "    test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"âœ… DataLoader ìƒì„± ì™„ë£Œ!\")\n",
        "    print(f\"   Train samples: {train_size:,} â†’ {len(train_loader)} batches\")\n",
        "    print(f\"   Val samples: {val_size:,} â†’ {len(val_loader)} batches\")\n",
        "    print(f\"   Test samples: {len(test_dataset):,} â†’ {len(test_loader)} batches\")\n",
        "    print(f\"   Batch size: {batch_size}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "# ===== ì‚¬ìš© ì˜ˆì‹œ =====\n",
        "# ì „ì²˜ë¦¬ ë° í† í°í™” ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ë³€ìˆ˜ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "# train_input_ids, train_attention_masks, train_labels_tensor\n",
        "# test_input_ids, test_attention_masks, test_labels_tensor\n",
        "\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    train_input_ids,      # í›ˆë ¨ ë°ì´í„° ì…ë ¥ ID\n",
        "    train_attention_masks, # í›ˆë ¨ ë°ì´í„° ì–´í…ì…˜ ë§ˆìŠ¤í¬\n",
        "    train_labels_tensor,  # í›ˆë ¨ ë ˆì´ë¸”\n",
        "    test_input_ids,       # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥ ID\n",
        "    test_attention_masks, # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì–´í…ì…˜ ë§ˆìŠ¤í¬\n",
        "    test_labels_tensor,   # í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”\n",
        "    batch_size=32,\n",
        "    val_ratio=0.2\n",
        ")\n",
        "\n",
        "# í™•ì¸\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“Š DataLoader ìƒ˜í”Œ í™•ì¸\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for batch in train_loader:\n",
        "    x, mask, y = batch # input_ids, attention_mask, label\n",
        "    print(f\"Train - ì…ë ¥ í…ì„œ shape: {x.shape}\")\n",
        "    print(f\"Train - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: {mask.shape}\")\n",
        "    print(f\"Train - ë ˆì´ë¸” shape: {y.shape}\")\n",
        "    break\n",
        "\n",
        "for batch in val_loader:\n",
        "    x, mask, y = batch # input_ids, attention_mask, label\n",
        "    print(f\"Val - ì…ë ¥ í…ì„œ shape: {x.shape}\")\n",
        "    print(f\"Val - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: {mask.shape}\")\n",
        "    print(f\"Val - ë ˆì´ë¸” shape: {y.shape}\")\n",
        "    break\n",
        "\n",
        "for batch in test_loader:\n",
        "    x, mask, y = batch # input_ids, attention_mask, label\n",
        "    print(f\"Test - ì…ë ¥ í…ì„œ shape: {x.shape}\")\n",
        "    print(f\"Test - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: {mask.shape}\")\n",
        "    print(f\"Test - ë ˆì´ë¸” shape: {y.shape}\")\n",
        "    break\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 17: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜\n",
        "VOCAB_SIZE = 8000                  # ë‹¨ì–´ ì‚¬ì „ì˜ í¬ê¸°\n",
        "EMBEDDING_DIM = 100                # ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›\n",
        "HIDDEN_DIM = 128                   # LSTMì˜ ì€ë‹‰ ìƒíƒœ ì°¨ì›\n",
        "OUTPUT_DIM = 1                     # ì¶œë ¥ ì°¨ì› (ê¸ì •=1, ë¶€ì •=0 -> 1ê°œ)\n",
        "N_LAYERS = 2                       # LSTM ë ˆì´ì–´ ê°œìˆ˜\n",
        "BIDIRECTIONAL = True               # ì–‘ë°©í–¥ RNN/LSTM ì—¬ë¶€\n",
        "DROPOUT_RATE = 0.2                 # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "PAD_IDX = 0                        # íŒ¨ë”© ì¸ë±ìŠ¤ (0)\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 18: LSTM ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. ì„ë² ë”© ë ˆì´ì–´\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # 2. LSTM ë ˆì´ì–´\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                           hidden_size=hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           batch_first=True,\n",
        "                           dropout=dropout)\n",
        "\n",
        "        # 3. FC ë ˆì´ì–´\n",
        "        fc_input_dim = hidden_dim * 2\n",
        "        self.fc = nn.Linear(fc_input_dim, output_dim)\n",
        "\n",
        "        # 4. ë“œë¡­ì•„ì›ƒ\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # 2. LSTM\n",
        "        _output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # 3. ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì€ë‹‰ ìƒíƒœ ê²°í•© (ì–‘ë°©í–¥ ì²˜ë¦¬)\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "        # 4. FC ë ˆì´ì–´ í†µê³¼\n",
        "        prediction = self.fc(hidden)\n",
        "\n",
        "        return prediction.squeeze(1)\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 19: í›ˆë ¨/í‰ê°€ í•¨ìˆ˜ ì •ì˜ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "# 0. GPU ì¥ì¹˜ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "# 2. í›ˆë ¨ í•¨ìˆ˜ ì •ì˜\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for texts, masks, labels in iterator: # Unpack 3 values: input_ids, attention_mask, labels\n",
        "        texts = texts.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(texts)\n",
        "        loss = criterion(predictions, labels.float())\n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # í´ë¦¬í•‘\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "# 3. í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, masks, labels in iterator: # Unpack 3 values: input_ids, attention_mask, labels\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predictions = model(texts)\n",
        "            loss = criterion(predictions, labels.float())\n",
        "            acc = binary_accuracy(predictions, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "# ================================================================================\n",
        "# âœ… ì…€ 20: ëª¨ë¸ í›ˆë ¨ (ê¸°ì¡´ ì½”ë“œ - ë³€ê²½ ì—†ìŒ)\n",
        "# ================================================================================\n",
        "# ëª¨ë¸ ì„¤ì •\n",
        "lstm_model = LSTMModel(\n",
        "    VOCAB_SIZE,\n",
        "    EMBEDDING_DIM,\n",
        "    HIDDEN_DIM,\n",
        "    OUTPUT_DIM,\n",
        "    N_LAYERS,\n",
        "    BIDIRECTIONAL,\n",
        "    DROPOUT_RATE,\n",
        "    PAD_IDX\n",
        ").to(device)\n",
        "\n",
        "save_path = 'best_model_lstm.pt'\n",
        "N_EPOCHS = 20\n",
        "patience = 5\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, lstm_model.parameters()), lr=0.0001)\n",
        "\n",
        "# Early stopping ë³€ìˆ˜\n",
        "best_valid_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "train_losses, train_accs, valid_losses, valid_accs = [], [], [], []\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"--- LSTM Model Training starts ---\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# í•™ìŠµ ë£¨í”„\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(lstm_model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(lstm_model, val_loader, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    # ê¸°ë¡\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    # Early Stopping\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(lstm_model.state_dict(), save_path)\n",
        "        patience_counter = 0\n",
        "        print(f'\\t>> Validation loss improved ({best_valid_loss:.3f}). Model saved.')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f'\\t>> Validation loss did not improve. Counter: {patience_counter}/{patience}')\n",
        "        if patience_counter >= patience:\n",
        "            print(f'--- Early stopping triggered after {epoch+1} epochs ---')\n",
        "            break\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ í‰ê°€\n",
        "print(f\"\\n--- Loading best LSTM model for test evaluation ---\")\n",
        "lstm_model.load_state_dict(torch.load(save_path))\n",
        "test_loss, test_acc = evaluate(lstm_model, test_loader, criterion)\n",
        "\n",
        "print(f\"\\n--- LSTM Model Test Results (Best Model) ---\")\n",
        "print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "print(f'\\tTest Acc:  {test_acc*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYKfSG-_aUtO",
        "outputId": "a48b2c24-7434-48c8-9cb7-63dca3c7174b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150000 entries, 0 to 149999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        150000 non-null  int64 \n",
            " 1   document  149995 non-null  object\n",
            " 2   label     150000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.4+ MB\n",
            "None\n",
            "================================================================================\n",
            "ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê²°ê³¼\n",
            "================================================================================\n",
            "\n",
            "[1] ì›ë³¸: ì–´ì œ ë³¸ ì˜í™” ì§„ì§œ ì¬ë°Œì—ˆìŒ!!! ë˜ ë³´ê³  ì‹¶ì–´ ğŸ˜‚\n",
            "    ê²°ê³¼: ì–´ì œ ë³¸ ì˜í™” ì§„ì§œ ì¬ë°Œì—ˆìŒ ! ë˜ ë³´ê³  ì‹¶ì–´\n",
            "\n",
            "[2] ì›ë³¸: ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ì— í•™êµì— ê°”ë‹¤. ê·¼ë° ë„ˆë¬´ ì¡¸ë ¸ìŒã…‹ã…‹ã…‹ã…‹\n",
            "    ê²°ê³¼: ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ í•™êµ ê°”ë‹¤ . ê·¼ë° ë„ˆë¬´ ì¡¸ë ¸ìŒ\n",
            "\n",
            "[3] ì›ë³¸: ë°¥ì€ ë¨¹ì—ˆë‹ˆ?? ì•„ì§ì´ì•¼... ì ì‹¬ì— ê°™ì´ ë¨¹ì!!!\n",
            "    ê²°ê³¼: ë°¥ì€ ë¨¹ì—ˆë‹ˆ ? ì•„ì§ì´ì•¼ . ì ì‹¬ ê°™ì´ ë¨¹ì !\n",
            "\n",
            "[4] ì›ë³¸: ë©”ìº… í˜•íƒœì†Œ ë¶„ì„ì€ í•œêµ­ì–´ ì²˜ë¦¬ì—ì„œ ë§ì´ ì‚¬ìš©ë¼ ğŸ‘\n",
            "    ê²°ê³¼: ë©”ìº… í˜•íƒœì†Œ ë¶„ì„ í•œêµ­ì–´ ì²˜ë¦¬ì—ì„œ ë§ì´ ì‚¬ìš©ë¼\n",
            "\n",
            "[5] ì›ë³¸: íŒŒì´ì¬ìœ¼ë¡œ í† í° ë¹ˆë„ì™€ í’ˆì‚¬ ë¶„í¬ë¥¼ ì‹œê°í™”í•´ ë³´ì!!!\n",
            "    ê²°ê³¼: íŒŒì´ì¬ í† í° ë¹ˆë„ í’ˆì‚¬ ë¶„í¬ ì‹œê°í™”í•´ ë³´ì !\n",
            "\n",
            "[6] ì›ë³¸: ìš”ì¦˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ RG êµ¬ì¶•ì„ ë§ì´ í•´!!\n",
            "    ê²°ê³¼: ìš”ì¦˜ ì½”ì‚¬ì¸ ìœ ì‚¬ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ rg êµ¬ì¶•ì„ ë§ì´ í•´ !\n",
            "\n",
            "[7] ì›ë³¸: ì—ì´ì „íŠ¸ëŠ” ì™¸ë¶€ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ ì‘ì—…ì„ ìë™í™”í•  ìˆ˜ ìˆì–´. êµ³!\n",
            "    ê²°ê³¼: ì—ì´ì „íŠ¸ ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œí•´ ì‘ì—…ì„ ìë™í™”í•  ìˆ˜ ìˆì–´ . êµ³ !\n",
            "\n",
            "[8] ì›ë³¸: ì´ ì˜í™” ì§„ì§œ ë¯¸ì³£ë‹¤!!! ë„ˆë¬´ ì¬ë°ŒìŒã…‹ã…‹ã…‹ã…‹\n",
            "    ê²°ê³¼: ì˜í™” ì§„ì§œ ë¯¸ì³¤ë‹¤ ! ë„ˆë¬´ ì¬ë°ŒìŒ\n",
            "\n",
            "[9] ì›ë³¸: ë°°ìš° ì—°ê¸° êµ³ì´ í›Œë¥­í–ˆìŒ, ìŠ¤í† ë¦¬ëŠ” ë´£ì§€ë§Œ...\n",
            "    ê²°ê³¼: ë°°ìš° ì—°ê¸° êµ³ì´ í›Œë¥­í–ˆìŒ , ìŠ¤í† ë¦¬ ë´¤ì§€ë§Œ .\n",
            "\n",
            "[10] ì›ë³¸: ì´ê±´ ã„±ã…Š ì˜í™”ë„¤, êµ¿êµ¿!\n",
            "    ê²°ê³¼: ì´ê±´ ê´œì°® ì˜í™”ë„¤ , êµ³êµ³ !\n",
            "\n",
            "================================================================================\n",
            "ì‹¤ì œ ë°ì´í„° ì ìš© ì˜ˆì‹œ\n",
            "================================================================================\n",
            "ì „ì²˜ë¦¬ ì „ ë°ì´í„° í¬ê¸°: 150000\n",
            "ê²°ì¸¡ì¹˜ ì œê±° í›„: 149995\n",
            "ë¹ˆ ë¬¸ìì—´ ì œê±° í›„: 149607\n",
            "ì¤‘ë³µ ì œê±° í›„: 144478\n",
            "ì „ì²˜ë¦¬ ì „ ë°ì´í„° í¬ê¸°: 50000\n",
            "ê²°ì¸¡ì¹˜ ì œê±° í›„: 49997\n",
            "ë¹ˆ ë¬¸ìì—´ ì œê±° í›„: 49843\n",
            "ì¤‘ë³µ ì œê±° í›„: 48700\n",
            "\n",
            "ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
            "Train ë°ì´í„°: 144478ê°œ\n",
            "Test ë°ì´í„°: 48700ê°œ\n",
            "\n",
            "ì „ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ:\n",
            "         id                                           document  label\n",
            "0   9976970                                ì•„ ë”ë¹™ . ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬      0\n",
            "1   3819312                   í  . í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„ . ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜      1\n",
            "2  10265843                                  ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤      0\n",
            "3   9045019                      êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ . ì†”ì§íˆ ì¬ë¯¸ ì—†ë‹¤ . í‰ì  ì¡°ì •      0\n",
            "4   6483659  ì‚¬ì´ëª¬í˜ê·¸ ìµì‚´ìŠ¤ëŸ° ì—°ê¸° ë‹ë³´ì˜€ë˜ ì˜í™” ! ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ...      1\n",
            "5   5403919        ë§‰ ê±¸ìŒë§ˆ ë—€ 3ì„¸ë¶€í„° ì´ˆë“±í•™êµ 1í•™ë…„ìƒì¸ 8ì‚´ìš©ì˜í™” . . ë³„ë°˜ê°œ ì•„ê¹Œì›€ .      0\n",
            "6   7797314                              ì›ì‘ ê¸´ì¥ê°ì„ ì œëŒ€ë¡œ ì‚´ë ¤ë‚´ì§€ëª»í–ˆë‹¤ .      0\n",
            "7   9443947  ë³„ ë°˜ê°œ ì•„ê¹ë‹¤ ìš•ë‚˜ì˜¨ë‹¤ ì´ì‘ê²½ ê¸¸ìš©ìš° ì—°ê¸°ìƒí™œì´ëª‡ë…„ì¸ì§€ . ì •ë§ ë°œë¡œí•´ ê·¸ê²ƒë³´ë‹¨ ...      0\n",
            "8   7156791                                ì•¡ì…˜ ì—†ëŠ”ë° ì¬ë¯¸ ìˆëŠ” ëª‡ì•ˆë˜ ì˜í™”      1\n",
            "9   5912145     ì™œì¼€ í‰ì  ë‚®ì€ê±´ë° ? ê½¤ ë³¼ë§Œí•œë° . í—ë¦¬ìš°ë“œì‹ í™”ë ¤í•¨ì—ë§Œ ë„ˆë¬´ ê¸¸ë“¤ì—¬ì ¸ ìˆë‚˜ ?      1\n",
            "\n",
            "================================================================================\n",
            "ğŸ”§ MECAB í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
            "================================================================================\n",
            "âœ… MECAB ë¡œë“œ ì™„ë£Œ\n",
            "âœ… MECAB ì •ìƒ ì‘ë™\n",
            "ë¶„ì„ ê²°ê³¼: ['ì´', 'ì˜í™”', 'ì •ë§', 'ì¬ë¯¸ìˆ', 'ì—ˆ', 'ì–´']\n",
            "\n",
            "ğŸ”„ MECAB í˜•íƒœì†Œ ë¶„ì„ ì²˜ë¦¬ ì¤‘...\n",
            "\n",
            "ğŸ“Š MECAB ë¶„ì„ ê²°ê³¼ ìƒ˜í”Œ:\n",
            "====================================================================================================\n",
            "\n",
            "[ìƒ˜í”Œ 1]\n",
            "  ì›ë³¸:      ì•„ ë”ë¹™ . ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬\n",
            "  í˜•íƒœì†Œ:    ì•„ ë” ë¹™ . ì§„ì§œ ì§œì¦ ë‚˜ ë„¤ìš” ëª©ì†Œë¦¬\n",
            "\n",
            "[ìƒ˜í”Œ 2]\n",
            "  ì›ë³¸:      í  . í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„ . ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜\n",
            "  í˜•íƒœì†Œ:    í  . í¬ìŠ¤í„° ë³´ê³  ì´ˆë”© ì˜í™” ì¤„ . ì˜¤ë²„ ì—°ê¸° ì¡°ì°¨ ê°€ë³ ì§€ ì•Š êµ¬ë‚˜\n",
            "\n",
            "[ìƒ˜í”Œ 3]\n",
            "  ì›ë³¸:      ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤\n",
            "  í˜•íƒœì†Œ:    ë„ˆë¬´ ì¬ ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤\n",
            "====================================================================================================\n",
            "\n",
            "ğŸ”„ MECAB í˜•íƒœì†Œ ë¶„ì„ ì²˜ë¦¬ ì¤‘...\n",
            "\n",
            "ğŸ“Š MECAB ë¶„ì„ ê²°ê³¼ ìƒ˜í”Œ:\n",
            "====================================================================================================\n",
            "\n",
            "[ìƒ˜í”Œ 1]\n",
            "  ì›ë³¸:      êµ³\n",
            "  í˜•íƒœì†Œ:    êµ³\n",
            "\n",
            "[ìƒ˜í”Œ 2]\n",
            "  ì›ë³¸:      gdntopclassintheclub\n",
            "  í˜•íƒœì†Œ:    gdntopclassintheclub\n",
            "\n",
            "[ìƒ˜í”Œ 3]\n",
            "  ì›ë³¸:      ë­ì•¼ í‰ì ë“¤ . ë‚˜ì˜ì§„ ì•Šì§€ë§Œ 10ì  ì§œë¦¬ ë”ë”ìš± ì•„ë‹ˆì–ì•„\n",
            "  í˜•íƒœì†Œ:    ë­ ì•¼ í‰ì  ë“¤ . ë‚˜ì˜ ì§„ ì•Š ì§€ë§Œ 10 ì  ì§œë¦¬ ë”ë”ìš± ì•„ë‹ˆ ì–ì•„\n",
            "====================================================================================================\n",
            "\n",
            "âœ… MECAB í˜•íƒœì†Œ ë¶„ì„ ì™„ë£Œ!\n",
            "   Train: 144478ê°œ ë¬¸ì¥ ë¶„ì„\n",
            "   Test: 48700ê°œ ë¬¸ì¥ ë¶„ì„\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "-rw-r--r-- 1 root root 373253 Nov 13 18:22 naver_spm.model\n",
            "-rw-r--r-- 1 root root 116006 Nov 13 18:22 naver_spm.vocab\n",
            "================================================================================\n",
            "ğŸ“Š SentencePiece í† í°í™” ì˜ˆì‹œ (MECAB í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)\n",
            "================================================================================\n",
            "ì›ë³¸ í…ìŠ¤íŠ¸:       ì´ ì˜í™” ì§„ì§œ ë¯¸ì³£ë‹¤!!! ë„ˆë¬´ ì¬ë°ŒìŒã…‹ã…‹ã…‹ã…‹\n",
            "ì •ê·œì‹ ì „ì²˜ë¦¬:     ì˜í™” ì§„ì§œ ë¯¸ì³¤ë‹¤ ! ë„ˆë¬´ ì¬ë°ŒìŒ\n",
            "MECAB í˜•íƒœì†Œ:      ì˜í™” ì§„ì§œ ë¯¸ì³¤ ë‹¤ ! ë„ˆë¬´ ì¬ë°Œ ìŒ\n",
            "Encoded IDs:       [2, 8, 78, 1936, 6, 31, 50, 76, 59, 3]\n",
            "Decoded Text:      ì˜í™” ì§„ì§œ ë¯¸ì³¤ ë‹¤ ! ë„ˆë¬´ ì¬ë°Œ ìŒ\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜\n",
            "================================================================================\n",
            "âœ… í›ˆë ¨ ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜ ì™„ë£Œ. (Shape: torch.Size([144478, 108]))\n",
            "âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° í† í°í™” ë° í…ì„œ ë³€í™˜ ì™„ë£Œ. (Shape: torch.Size([48700, 110]))\n",
            "âœ… DataLoader ìƒì„± ì™„ë£Œ!\n",
            "   Train samples: 115,583 â†’ 3612 batches\n",
            "   Val samples: 28,895 â†’ 903 batches\n",
            "   Test samples: 48,700 â†’ 1522 batches\n",
            "   Batch size: 32\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š DataLoader ìƒ˜í”Œ í™•ì¸\n",
            "============================================================\n",
            "Train - ì…ë ¥ í…ì„œ shape: torch.Size([32, 108])\n",
            "Train - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: torch.Size([32, 108])\n",
            "Train - ë ˆì´ë¸” shape: torch.Size([32])\n",
            "Val - ì…ë ¥ í…ì„œ shape: torch.Size([32, 108])\n",
            "Val - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: torch.Size([32, 108])\n",
            "Val - ë ˆì´ë¸” shape: torch.Size([32])\n",
            "Test - ì…ë ¥ í…ì„œ shape: torch.Size([32, 110])\n",
            "Test - ì–´í…ì…˜ ë§ˆìŠ¤í¬ shape: torch.Size([32, 110])\n",
            "Test - ë ˆì´ë¸” shape: torch.Size([32])\n",
            "Using device: cuda\n",
            "\n",
            "============================================================\n",
            "--- LSTM Model Training starts ---\n",
            "============================================================\n",
            "\n",
            "Epoch: 01 | Time: 0m 31s\n",
            "\tTrain Loss: 0.504 | Train Acc: 74.52%\n",
            "\t Val. Loss: 0.433 |  Val. Acc: 79.56%\n",
            "\t>> Validation loss improved (0.433). Model saved.\n",
            "Epoch: 02 | Time: 0m 31s\n",
            "\tTrain Loss: 0.402 | Train Acc: 81.93%\n",
            "\t Val. Loss: 0.427 |  Val. Acc: 80.49%\n",
            "\t>> Validation loss improved (0.427). Model saved.\n",
            "Epoch: 03 | Time: 0m 33s\n",
            "\tTrain Loss: 0.365 | Train Acc: 83.98%\n",
            "\t Val. Loss: 0.385 |  Val. Acc: 82.59%\n",
            "\t>> Validation loss improved (0.385). Model saved.\n",
            "Epoch: 04 | Time: 0m 33s\n",
            "\tTrain Loss: 0.342 | Train Acc: 85.16%\n",
            "\t Val. Loss: 0.384 |  Val. Acc: 82.54%\n",
            "\t>> Validation loss improved (0.384). Model saved.\n",
            "Epoch: 05 | Time: 0m 33s\n",
            "\tTrain Loss: 0.321 | Train Acc: 86.23%\n",
            "\t Val. Loss: 0.373 |  Val. Acc: 83.65%\n",
            "\t>> Validation loss improved (0.373). Model saved.\n",
            "Epoch: 06 | Time: 0m 34s\n",
            "\tTrain Loss: 0.305 | Train Acc: 87.11%\n",
            "\t Val. Loss: 0.366 |  Val. Acc: 83.94%\n",
            "\t>> Validation loss improved (0.366). Model saved.\n",
            "Epoch: 07 | Time: 0m 33s\n",
            "\tTrain Loss: 0.291 | Train Acc: 87.96%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 84.28%\n",
            "\t>> Validation loss improved (0.361). Model saved.\n",
            "Epoch: 08 | Time: 0m 33s\n",
            "\tTrain Loss: 0.276 | Train Acc: 88.67%\n",
            "\t Val. Loss: 0.367 |  Val. Acc: 84.79%\n",
            "\t>> Validation loss did not improve. Counter: 1/5\n",
            "Epoch: 09 | Time: 0m 33s\n",
            "\tTrain Loss: 0.262 | Train Acc: 89.44%\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 84.32%\n",
            "\t>> Validation loss did not improve. Counter: 2/5\n",
            "Epoch: 10 | Time: 0m 33s\n",
            "\tTrain Loss: 0.251 | Train Acc: 89.99%\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 84.68%\n",
            "\t>> Validation loss did not improve. Counter: 3/5\n",
            "Epoch: 11 | Time: 0m 33s\n",
            "\tTrain Loss: 0.237 | Train Acc: 90.65%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 84.19%\n",
            "\t>> Validation loss did not improve. Counter: 4/5\n",
            "Epoch: 12 | Time: 0m 33s\n",
            "\tTrain Loss: 0.226 | Train Acc: 91.14%\n",
            "\t Val. Loss: 0.396 |  Val. Acc: 84.50%\n",
            "\t>> Validation loss did not improve. Counter: 5/5\n",
            "--- Early stopping triggered after 12 epochs ---\n",
            "\n",
            "--- Loading best LSTM model for test evaluation ---\n",
            "\n",
            "--- LSTM Model Test Results (Best Model) ---\n",
            "\tTest Loss: 0.360\n",
            "\tTest Acc:  84.42%\n"
          ]
        }
      ]
    }
  ]
}